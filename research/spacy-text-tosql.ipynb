{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy text to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (1.57.4)\n",
      "Requirement already satisfied: spacy in ./.venv/lib/python3.12/site-packages (3.8.3)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in ./.venv/lib/python3.12/site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from spacy) (75.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai spacy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema_terms: ['customers', 'customers.customer_id', 'customers.name', 'customers.email', 'customers.location', 'orders', 'orders.order_id', 'orders.customer_id', 'orders.product_id', 'orders.quantity', 'orders.order_date', 'products', 'products.product_id', 'products.name', 'products.price']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # 'md' model provides vectors for similarity\n",
    "\n",
    "# Define schema terms\n",
    "schema = {\n",
    "    \"customers\": [\"customer_id\", \"name\", \"email\", \"location\"],\n",
    "    \"orders\": [\"order_id\", \"customer_id\", \"product_id\", \"quantity\", \"order_date\"],\n",
    "    \"products\": [\"product_id\", \"name\", \"price\"]\n",
    "}\n",
    "\n",
    "# Flatten the schema for matching\n",
    "schema_terms = []\n",
    "for table, columns in schema.items():\n",
    "    schema_terms.append(table)\n",
    "    schema_terms.extend([f\"{table}.{col}\" for col in columns])\n",
    "\n",
    "print('schema_terms:', schema_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Access the OpenAI key\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_items_spacy(query, top_k=3):\n",
    "    # Parse query with spaCy\n",
    "    query_doc = nlp(query)\n",
    "\n",
    "    # Calculate similarity between query and schema terms\n",
    "    relevance_scores = []\n",
    "    for term in schema_terms:\n",
    "        schema_doc = nlp(term)\n",
    "        score = query_doc.similarity(schema_doc)\n",
    "        relevance_scores.append((term, score))\n",
    "    \n",
    "    # Sort terms by relevance score\n",
    "    relevance_scores = sorted(relevance_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-k relevant terms\n",
    "    relevant_items = relevance_scores[:top_k]\n",
    "    return relevant_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query_spacy(query):\n",
    "    # Get top relevant schema items\n",
    "    relevant_items = get_relevant_items_spacy(query)\n",
    "    \n",
    "    # Construct prompt with relevant schema items\n",
    "    relevant_schema_text = \"\\n\".join([f\"- {item[0]}\" for item in relevant_items])\n",
    "    prompt = (\n",
    "        f\"Given the following SQL database schema and the query request, generate an SQL query.\\n\\n\"\n",
    "        f\"Schema:\\n{relevant_schema_text}\\n\\n\"\n",
    "        f\"Query request: {query}\\n\\n\"\n",
    "        \"SQL Query:\"\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Sql for developer get data\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Extract and return SQL query from response\n",
    "    sql_query = completion.choices[0].message\n",
    "    return sql_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_64882/139854315.py:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  score = query_doc.similarity(schema_doc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: ChatCompletionMessage(content=\"To retrieve all orders placed by customers located in New York, you can use a SQL query that joins the `orders` table with the `customers` table. Here's how the query might look:\\n\\n```sql\\nSELECT o.*\\nFROM orders o\\nJOIN customers c ON o.customer_id = c.id\\nWHERE c.city = 'New York';\\n```\\n\\nIn this query:\\n- `o.*` selects all columns from the `orders` table.\\n- We join the `orders` table (`o`) with the `customers` table (`c`) on their respective customer ID fields.\\n- The `WHERE` clause filters the results to include only those customers whose city is 'New York'. \\n\\nMake sure to adjust the column names in the `JOIN` clause according to your actual database schema if they are named differently.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"Show me all orders placed by customers in New York\"\n",
    "sql_query = generate_sql_query_spacy(query)\n",
    "print(\"Generated SQL Query:\", sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.1.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Downloading mysql_connector_python-9.1.0-py2.py3-none-any.whl (381 kB)\n",
      "Installing collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'int unsigned', 'name': 'varchar(255)', 'order': 'smallint', 'created_at': 'datetime', 'updated_at': 'datetime', 'deleted_at': 'datetime'}\n"
     ]
    }
   ],
   "source": [
    "# write code connect mysql database and pluck all schema table\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "# Establish the connection\n",
    "conn = mysql.connector.connect(\n",
    "    host='127.0.0.1',\n",
    "    user='root',\n",
    "    password='root',\n",
    "    database='eccubedb',\n",
    "    port=13306\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute the query to get all tables in the schema\n",
    "cursor.execute(\"SHOW TABLES\")\n",
    "\n",
    "# Fetch all tables\n",
    "tables = cursor.fetchall()\n",
    "# Initialize the structure dictionary\n",
    "structure = {}\n",
    "\n",
    "# Iterate over the tables\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    # Execute the query to get all columns of the table\n",
    "    cursor.execute(f\"SHOW COLUMNS FROM {table_name}\")\n",
    "\n",
    "    # Fetch all columns\n",
    "    columns = cursor.fetchall()\n",
    "    \n",
    "    # Add table to the structure dictionary\n",
    "    structure[table_name] = {}\n",
    "    \n",
    "    # Iterate over the columns\n",
    "    for column in columns:\n",
    "        column_name = column[0]\n",
    "        column_type = column[1]\n",
    "        # Add column name and type to the table dictionary\n",
    "        structure[table_name][column_name] = column_type\n",
    "\n",
    "# Print the structure dictionary\n",
    "print(structure['dcm_areas'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema_terms: ['dcm_areas', 'dcm_areas.id ', 'dcm_areas.name ', 'dcm_areas.order ', 'dcm_areas.created_at ', 'dcm_areas.updated_at ', 'dcm_areas.deleted_at ', 'dcm_atms', 'dcm_atms.id ', 'dcm_atms.shop_id ', 'dcm_atms.name ', 'dcm_atms.business_hour ', 'dcm_atms.order ', 'dcm_atms.created_at ', 'dcm_atms.updated_at ', 'dcm_atms.deleted_at ', 'dcm_auth_lock_temporary', 'dcm_auth_lock_temporary.id ', 'dcm_auth_lock_temporary.email ', 'dcm_auth_lock_temporary.times_of_fail ']\n"
     ]
    }
   ],
   "source": [
    "# Flatten the schema for matching\n",
    "schema_terms = []\n",
    "for table, columns in structure.items():\n",
    "    schema_terms.append(table)\n",
    "    schema_terms.extend([f\"{table}.{col} \" for col in columns])\n",
    "\n",
    "print('schema_terms:', schema_terms[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (0.3.12)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.12/site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain) (3.11.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.25)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.3)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain) (0.2.3)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./.venv/lib/python3.12/site-packages (from langchain) (2.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.55.3 in ./.venv/lib/python3.12/site-packages (from langchain-openai) (1.57.4)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.12/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class TableExtract(BaseModel):\n",
    "    \"\"\"Information table relevant to the query\"\"\"\n",
    "    tables: Optional[list] = Field(None, description=\"Name tables relevant to the query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert database engineer. \"\n",
    "            \"Now extract relevant tables to this query\"\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To extract relevant tables for this query, we would need tables related to customers, orders, and payments. Here's an example of the relevant tables and their columns that could be used for this query:\\n\\n1. Customers table:\\n   - customer_id (Primary key)\\n   - customer_name\\n   - customer_email\\n   - ...\\n\\n2. Orders table:\\n   - order_id (Primary key)\\n   - customer_id (Foreign key referencing Customers table)\\n   - order_date\\n   - ...\\n\\n3. Payments table:\\n   - payment_id (Primary key)\\n   - order_id (Foreign key referencing Orders table)\\n   - total_payment\\n   - payment_date\\n   - ...\\n\\nWith these tables, we can write a query to find the top customer with the highest number of orders (count by total_payment) in the current month. The query might look something like this:\\n\\n```sql\\nSELECT c.customer_id, c.customer_name, COUNT(o.order_id) AS order_count\\nFROM Customers c\\nJOIN Orders o ON c.customer_id = o.customer_id\\nJOIN Payments p ON o.order_id = p.order_id\\nWHERE MONTH(p.payment_date) = MONTH(CURRENT_DATE()) AND YEAR(p.payment_date) = YEAR(CURRENT_DATE())\\nGROUP BY c.customer_id, c.customer_name\\nORDER BY order_count DESC\\nLIMIT 1;\\n```\\n\\nThis query will list the customer with the highest number of orders (counted by total_payment) in the current month. It joins the Customers, Orders, and Payments tables based on the relationships between them and filters the results based on the payment date of the current month.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 323, 'prompt_tokens': 39, 'total_tokens': 362, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3d63097c-0841-43e9-933a-7824bbd61d1f-0', usage_metadata={'input_tokens': 39, 'output_tokens': 323, 'total_tokens': 362, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"top customer having highest order (count by total_payment) in this month\"\n",
    "\n",
    "chat1= prompt.format_messages(text=query)\n",
    "\n",
    "model.invoke(chat1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "class SchemaAnalyzer:\n",
    "    def __init__(self, host, user, password, database, port):\n",
    "        self.conn = mysql.connector.connect(\n",
    "            host=host,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            database=database,\n",
    "            port=port\n",
    "        )\n",
    "        self.cursor = self.conn.cursor()\n",
    "        # self.nlp = spacy.load(\"en_core_web_md\")\n",
    "        self.schema_terms = self._get_schema_terms()\n",
    "\n",
    "    def _get_schema_terms(self):\n",
    "        self.cursor.execute(\"SHOW TABLES\")\n",
    "        tables = self.cursor.fetchall()\n",
    "        schema_terms = []\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            schema_terms.append(table_name)\n",
    "            self.cursor.execute(f\"SHOW COLUMNS FROM {table_name}\")\n",
    "            columns = self.cursor.fetchall()\n",
    "            for column in columns:\n",
    "                column_name = column[0]\n",
    "                term_add = f\"{table_name}.{column_name}\"\n",
    "                schema_terms.append(term_add)\n",
    "        return schema_terms\n",
    "\n",
    "    def get_relevant_items_spacy(self, query, top_k=3):\n",
    "        relevance_scores = []\n",
    "        for term in self.schema_terms:\n",
    "            score = fuzz.partial_ratio(query, term)\n",
    "            relevance_scores.append((term, score))\n",
    "            # print('term:', term, 'score:', score)\n",
    "        relevance_scores = sorted(relevance_scores, key=lambda x: x[1], reverse=True)\n",
    "        relevant_items = relevance_scores[:top_k]\n",
    "        return relevant_items\n",
    "\n",
    "    def generate_sql_query_spacy(self, query):\n",
    "        relevant_items = self.get_relevant_items_spacy(query, 6)\n",
    "        print('relevant_items', relevant_items)\n",
    "        relevant_schema_text = \"\\n\".join([f\"- {item[0]}\" for item in relevant_items])\n",
    "        # prompt = (\n",
    "        #     f\"Given the following SQL database schema and the query request, generate an SQL query.\\n\\n\"\n",
    "        #     f\"Schema:\\n{relevant_schema_text}\\n\\n\"\n",
    "        #     f\"Query request: {query}\\n\\n\"\n",
    "        #     \"SQL Query:\"\n",
    "        # )\n",
    "\n",
    "        # # Assuming you have a client object for OpenAI's API\n",
    "        # completion = client.chat.completions.create(\n",
    "        #     model=\"gpt-4o\",\n",
    "        #     messages=[\n",
    "        #         {\"role\": \"system\", \"content\": prompt},\n",
    "        #         {\n",
    "        #             \"role\": \"user\",\n",
    "        #             \"content\": \"Sql for developer get data\"\n",
    "        #         }\n",
    "        #     ]\n",
    "        # )\n",
    "\n",
    "        # sql_query = completion.choices[0].message\n",
    "        # return sql_query\n",
    "        return 'alo alo'\n",
    "\n",
    "    def close_connection(self):\n",
    "        self.cursor.close()\n",
    "        self.conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_items [('dtb_payment', 81.81818181818181), ('pt_customer', 81.81818181818181), ('dtb_customer', 75.0), ('dtb_payment.id', 71.42857142857143), ('pt_customer.id', 69.23076923076923), ('dtb_customer.id', 66.66666666666667)]\n",
      "alo alo\n"
     ]
    }
   ],
   "source": [
    "analyzer = SchemaAnalyzer(\n",
    "    host='127.0.0.1',\n",
    "    user='root',\n",
    "    password='root',\n",
    "    database='eccubedb',\n",
    "    port=13306\n",
    ")\n",
    "\n",
    "query = \"top customer having highest order (count by total_payment) in this month\"\n",
    "sql_query = analyzer.generate_sql_query_spacy(query)\n",
    "print(sql_query)\n",
    "analyzer.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
